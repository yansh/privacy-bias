<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Privacy Bias in Language Models: A Contextual Integrity-based Auditing Metric</title>

  <!-- Bootstrap -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">

  <link href="style.css" rel="stylesheet">
</head>

<body>
<nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top shadow">
  <div class="container-fluid">
    <!--<a class="navbar-brand" href="#">
      Privacy Bias in Language Models: A Contextual Integrity-based Auditing Metric
    </a>-->

    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarsExampleDefault">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarsExampleDefault">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
        <!--<li class="nav-item"><a class="nav-link" href="#citation">About</a></li>-->
      </ul>
    </div>
  </div>
</nav>

<section id="paper-header" class="my-5 section-block text-center">
  <h1 class="paper-title">
    Privacy Bias in Language Models: A Contextual Integrity-based Auditing Metric
  </h1>
  <p class="paper-authors mt-3">
    <a href="https://shvartzshnaider.com" target="_blank">Yan Shvartzshnaider</a> (York University)  
    <a href="https://vasishtduddu.github.io" target="_blank">Vasisht Duddu</a> (Waterloo University)
  </p>
</section>

<div class="container" style="margin-top: 90px;">

  <section id="abstract" class="my-5 section-block">
    <h2>Abstract</h2>
    <p>
      <p style="font-family: Georgia, serif; line-height: 1.6; font-size: 1.05rem; color: #222;">
        As large language models (LLMs) become increasingly embedded within sociotechnical systems, 
        it is essential to scrutinize the <strong>privacy biases</strong> they may exhibit. We define 
        <strong>privacy bias</strong> as the appropriateness of information flows in the responses 
        generated by LLMs. When the observed privacy bias deviates from expected norms, this discrepancy—
        referred to as the <strong>privacy bias delta</strong>—may signal potential privacy violations.
      </p>

      <p style="font-family: Georgia, serif; line-height: 1.6; font-size: 1.05rem; color: #222;">
        Using privacy bias as an auditing metric offers several benefits: 
        <span style="display: block; margin-left: 1.2em; margin-top: 0.4em;">
          (a) it enables <strong>model trainers</strong> to assess the ethical and societal implications of LLMs,<br>
          (b) it aids <strong>service providers</strong> in selecting context-appropriate LLMs,<br>
          (c) it helps <strong>policymakers</strong> evaluate the privacy appropriateness of deployed models.
        </span>
      </p>

      <p style="font-family: Georgia, serif; line-height: 1.6; font-size: 1.05rem; color: #222;">
        To address these concerns, we pose a novel research question: 
        <em>How can we reliably measure privacy biases in LLMs, and what factors influence them?</em> 
        In response, we introduce a contextual-integrity-based methodology for evaluating responses 
        from various LLMs. Our approach accounts for sensitivity across prompt variations, a major 
        obstacle in privacy bias assessment. Finally, we examine how model capacity and optimization choices 
        shape these biases.
      </p>
    </p>
  </section>

  <section id="results" class="my-5 section-block">
    <h2>Results and main takeaways</h2>

    <div class="row mt-4">
      <h3>Demonstrating Prompt Sensitivity</h3>
      <div class="col-md-6">
        <img src="images/Figure3.png" class="img-fluid rounded shadow-sm" alt="Figure 3">
        <p class="text-muted">Distribution of Responses: Responses across LLMs and prompt variations before filtering with thresholds.</p>
        <div >
          <rating-legend ></rating-legend>
        </div>
      </div>
      <div class="col-md-6">
        <img src="images/Figure5.png" class="img-fluid rounded shadow-sm" alt="Figure 2">
        <p class="text-muted">Prompt Sensitivity by re-ordering Likert scale. LLMs show significant variance due to prompt variation, with three random Likert scale orders per prompt.</p>
      </div>
    </div>

    <div class="card takeaway-card mb-3 shadow-sm" style="border-left: 5px solid blue;">
      <div class="card-body">
        <h5 class="takeaway-title">Takeaway</h5>
        <p class="takeaway-text">
          We observe significant variance in responses due to paraphrasing
          and changing the Likert scale order, which hinders the reliable
          evaluation of privacy biases.
        </p>
      </div>
    </div>

    <section id="results" class="my-5 section-block">
      <h3>Identifying Privacy Biases</h3>

      <div class="col-md-7 text-center mx-auto">
        <img src="images/Figure7.png" class="img-fluid rounded shadow-sm" alt="Figure 7">
      </div>

      <br/>
      <p class="text-muted">
        Privacy biases for sender “fitness tracker” and
        “personal assistant” in <span style="color: blue;">gpt-4o-mini</span> (top right triangle) and
        <span style="color: blue;">llama-3.1-8B</span> (bottom left triangle) for IoT. We have senders
        (left), subjects and information type (bottom), recipients
        (top), and transmission principles (right).
      </p>

      <rating-legend></rating-legend>

      <div class="card takeaway-card mb-3 shadow-sm" style="border-left: 5px solid blue;">
        <div class="card-body">
          <h5 class="takeaway-title">Takeaway</h5>
          <p class="takeaway-text">
            <span style="color: blue;">gpt-4o-mini</span> and 
            <span style="color: blue;">llama-3.1-8B</span> exhibit the signals for several
            notable privacy biases. Across all senders, information types, and
            recipients, for fixed transmission principles like 
            <em>stored indefinitely</em> and <em>used for advertising</em>, 
            <span style="color: blue;">gpt-4o-mini</span> is less conservative with
            privacy biases ranging from <em>strongly acceptable</em> to 
            <em>somewhat acceptable</em>. On the contrary, 
            <span style="color: blue;">llama-3.1-8B</span> is more conservative with
            the responses stated as <em>somewhat unacceptable</em>. For both LLMs,
            the privacy biases for a transmission principle such as 
            <em>if the owner gives consent</em> are identified as 
            <em>somewhat/strongly acceptable</em>.
          </p>
        </div>
      </div>

      <div class="row mt-4">
        <h3>Demonstrating Impact of LLM Configuration</h3>

        <!-- Center Figure 8 -->
        <div class="row justify-content-center mb-4">
          <div class="col-md-6 text-center">
            <img src="images/Figure8.png" class="img-fluid rounded shadow-sm" alt="Figure 8">
            <p class="text-muted">
              Base LLMs with different capacities. Each square indicates a privacy bias for a specific information
              flow. Privacy biases can also be identified across a column, row, or matrix, by fixing different
              parameters. We include <span style="color: blue;">tulu-2-7B</span> (top triangle) and 
              <span style="color: blue;">tulu-2-13B</span> (bottom triangle). 
            </p>
          </div>
        </div>

        <!-- Figures 9 and 10 side by side -->
        <div class="row">
          <div class="col-md-6">
            <img src="images/Figure9.png" class="img-fluid rounded shadow-sm" alt="Figure 9">
            <p class="text-muted">
              Base vs. Aligned LLMs: 
              <span style="color: blue;">tulu-2-7B</span> (top), 
              <span style="color: blue;">tulu-2-13B</span> (right), 
              <span style="color: blue;">tulu-2-dpo-7B</span> (down), and 
              <span style="color: blue;">tulu-2-dpo-13B</span> (left)
            </p>
          </div>

          <div class="col-md-6">
            <img src="images/Figure10.png" class="img-fluid rounded shadow-sm" alt="Figure 10">
            <p class="text-muted">
              Base vs. Quantized LLMs: 
              <span style="color: blue;">tulu-2-7B</span> (top), 
              <span style="color: blue;">tulu-2-13B</span> (right), 
              <span style="color: blue;">tulu-2-7B-AWQ</span> (down), and
              <span style="color: blue;">tulu-2-13B-AWQ</span> (left).
            </p>
          </div>

          <p class="text-muted">
            <!--Base LLMs with alignment (<b>left</b>) and quantization (<b>right</b>):-->
            Each square indicates a privacy bias for a specific information flow. Privacy biases can be identified
            across a column, row, or matrix by fixing different parameters. Senders (left), subjects and their
            information (<il>bottom</il>), recipients (<il>top</il>), and transmission principles (right). Empty blocks indicate that
            at least one of the four LLMs did not give consistent responses. See Appendix: Figures 13 and 14 for 
            the complete set.
          </p>
        </div>

        <!-- Takeaway Card -->
        <div class="card takeaway-card mb-3 shadow-sm" style="border-left: 5px solid blue;">
          <div class="card-body">
            <h5 class="takeaway-title">Takeaway</h5>
            <p class="takeaway-text">
              Privacy biases vary across different capacities and optimizations, even with a similar training dataset. 
              Model trainers need to consider these effects when choosing their LLM configuration.
            </p>
          </div>
        </div>
      </div>

    </section>




<section id="code" class="section-block">
  <h2><span class="repo-card-icon"></span>Results and code</h2>
  <p>
    Access the full project source code here:
    <a class="repo-link" href="https://github.com/yansh/privacy-bias" target="_blank">
   here
    </a>.
  </p>
</section>

<section id="citation" class="my-5 section-block">
  <h2>Citation</h2>

  <div class="card publication-card shadow-sm">
    <div class="card-body">
  <p class="apa-citation">
    Shvartzshnaider, Y., & Duddu, V. (2026).
    <i>Privacy Bias in Language Models: A Contextual Integrity-based Auditing Metric</i>.
    Proceedings on Privacy Enhancing Technologies.
</p>


      <button class="btn btn-primary btn-sm" id="bibtexToggle" onclick="toggleBibtex()">
        Show BibTeX
      </button>
      <button class="btn btn-outline-secondary btn-sm ms-2" id="bibtexCopy" onclick="copyBibtex()" style="display:none;">
        Copy BibTeX
      </button>

      <pre id="bibtex-block" class="mt-3 bibtex-block" style="display:none;">
@Article{PoPETS:PrivacyBias26,
  author    =   "Yan Shvartzshnaider and Vasisht Duddu",
  title     =   "{Privacy Bias in Language Models: A Contextual Integrity-based Auditing Metric}",
  year      =   2026,
  volume    =   2026,
  journal   =   "{Proceedings on Privacy Enhancing Technologies}",
}
      </pre>

    </div>
  </div>
</section>

<script>
function toggleBibtex() {
  const block = document.getElementById("bibtex-block");
  const toggleBtn = document.getElementById("bibtexToggle");
  const copyBtn = document.getElementById("bibtexCopy");

  if (block.style.display === "none") {
    block.style.display = "block";
    copyBtn.style.display = "inline-block";
    toggleBtn.innerText = "Hide BibTeX";
  } else {
    block.style.display = "none";
    copyBtn.style.display = "none";
    toggleBtn.innerText = "Show BibTeX";
  }
}

function copyBibtex() {
  const text = document.getElementById("bibtex-block").innerText;
  navigator.clipboard.writeText(text);
  alert("BibTeX copied to clipboard!");
}
</script>


</div>
<script>
class RatingLegend extends HTMLElement {
  connectedCallback() {
    this.innerHTML = `
      <style>
        .legend { border:3px solid black; padding:12px 16px; display:flex; flex-wrap:wrap; gap:20px; align-items:center; font-size:1.6rem; font-family:serif; transform:scale(0.7); transform-origin:top center;  width: 100%;   }
        .legend-item { display:flex; align-items:center; gap:8px; }
        .legend-box { width:28px; height:28px; border:3px solid black; display:inline-block; }        
      </style>

      <div class="legend">
        <div class="legend-item"><span class="legend-box" style="background:#c8c8c8;"></span> Invalid answer</div>
        <div class="legend-item"><span class="legend-box" style="background:#8b0000;"></span> Strongly unacceptable</div>
        <div class="legend-item"><span class="legend-box" style="background:#ff8a8a;"></span> Somewhat unacceptable</div>
        <div class="legend-item"><span class="legend-box" style="background:#fff200;"></span> Neutral</div>
        <div class="legend-item"><span class="legend-box" style="background:#66ff99;"></span> Somewhat acceptable</div>
        <div class="legend-item"><span class="legend-box" style="background:#006400;"></span> Strongly acceptable</div>
      </div>
    `;
  }
}
customElements.define("rating-legend", RatingLegend);
</script>

<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
